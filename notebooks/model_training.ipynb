MODEL_TRAINING_NOTEBOOK = {
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# BOQ Generator - Model Training\n",
                "\n",
                "This notebook implements and trains machine learning models for the BOQ generator system."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import json\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
                "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, classification_report\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "import joblib\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load and Prepare Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Load processed data\n",
                "with open('../data/processed_products.json', 'r') as f:\n",
                "    products_data = json.load(f)\n",
                "\n",
                "df = pd.DataFrame(products_data)\n",
                "print(f\"Dataset loaded: {df.shape}\")\n",
                "print(f\"Columns: {df.columns.tolist()}\")\n",
                "\n",
                "# Filter products with valid prices\n",
                "df_priced = df[df['price'] > 0].copy()\n",
                "print(f\"Products with valid prices: {len(df_priced)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "def extract_features(df):\n",
                "    \"\"\"Extract features for ML models\"\"\"\n",
                "    features_df = df.copy()\n",
                "    \n",
                "    # Text features\n",
                "    features_df['description_length'] = features_df['description'].str.len()\n",
                "    features_df['word_count'] = features_df['description'].str.split().str.len()\n",
                "    \n",
                "    # Categorical encoding\n",
                "    le_company = LabelEncoder()\n",
                "    le_category = LabelEncoder()\n",
                "    \n",
                "    features_df['company_encoded'] = le_company.fit_transform(features_df['company'])\n",
                "    features_df['category_encoded'] = le_category.fit_transform(features_df['category'])\n",
                "    \n",
                "    # Compatibility features\n",
                "    features_df['compatibility_count'] = features_df['compatibility'].apply(\n",
                "        lambda x: len(x) if isinstance(x, list) else 0\n",
                "    )\n",
                "    \n",
                "    # Specifications features\n",
                "    features_df['spec_count'] = features_df['specifications'].apply(\n",
                "        lambda x: len(x) if isinstance(x, dict) else 0\n",
                "    )\n",
                "    \n",
                "    return features_df, le_company, le_category\n",
                "\n",
                "# Extract features\n",
                "features_df, le_company, le_category = extract_features(df_priced)\n",
                "print(\"Feature engineering completed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Text Vectorization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Create TF-IDF vectors for product descriptions\n",
                "tfidf_vectorizer = TfidfVectorizer(\n",
                "    max_features=1000,\n",
                "    stop_words='english',\n",
                "    ngram_range=(1, 2),\n",
                "    min_df=2\n",
                ")\n",
                "\n",
                "# Fit and transform descriptions\n",
                "tfidf_matrix = tfidf_vectorizer.fit_transform(features_df['description'])\n",
                "tfidf_df = pd.DataFrame(\n",
                "    tfidf_matrix.toarray(),\n",
                "    columns=[f'tfidf_{i}' for i in range(tfidf_matrix.shape[1])],\n",
                "    index=features_df.index\n",
                ")\n",
                "\n",
                "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prepare Training Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Select numerical features\n",
                "numerical_features = [\n",
                "    'description_length', 'word_count', 'company_encoded', \n",
                "    'category_encoded', 'compatibility_count', 'spec_count'\n",
                "]\n",
                "\n",
                "# Combine numerical and text features\n",
                "X_numerical = features_df[numerical_features]\n",
                "X_combined = pd.concat([X_numerical, tfidf_df], axis=1)\n",
                "\n",
                "# Target variable (log-transformed price for better distribution)\n",
                "y = np.log1p(features_df['price'])\n",
                "\n",
                "print(f\"Feature matrix shape: {X_combined.shape}\")\n",
                "print(f\"Target shape: {y.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train-Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Split data\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X_combined, y, test_size=0.2, random_state=42, stratify=features_df['category']\n",
                ")\n",
                "\n",
                "print(f\"Training set: {X_train.shape}\")\n",
                "print(f\"Test set: {X_test.shape}\")\n",
                "\n",
                "# Scale features\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(\"Feature scaling completed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Price Prediction Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Random Forest for price prediction\n",
                "rf_price = RandomForestRegressor(\n",
                "    n_estimators=100,\n",
                "    max_depth=20,\n",
                "    min_samples_split=5,\n",
                "    min_samples_leaf=2,\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "# Train model\n",
                "rf_price.fit(X_train, y_train)\n",
                "\n",
                "# Predictions\n",
                "y_pred_train = rf_price.predict(X_train)\n",
                "y_pred_test = rf_price.predict(X_test)\n",
                "\n",
                "# Evaluate\n",
                "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
                "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
                "train_r2 = r2_score(y_train, y_pred_train)\n",
                "test_r2 = r2_score(y_test, y_pred_test)\n",
                "\n",
                "print(f\"Price Prediction Results:\")\n",
                "print(f\"Train RMSE: {train_rmse:.4f}\")\n",
                "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
                "print(f\"Train R²: {train_r2:.4f}\")\n",
                "print(f\"Test R²: {test_r2:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Category Classification Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Random Forest for category classification\n",
                "rf_category = RandomForestClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=20,\n",
                "    min_samples_split=5,\n",
                "    min_samples_leaf=2,\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "# Prepare category targets\n",
                "y_category_train = features_df.loc[X_train.index, 'category']\n",
                "y_category_test = features_df.loc[X_test.index, 'category']\n",
                "\n",
                "# Train model\n",
                "rf_category.fit(X_train, y_category_train)\n",
                "\n",
                "# Predictions\n",
                "y_cat_pred_test = rf_category.predict(X_test)\n",
                "\n",
                "# Evaluate\n",
                "print(\"Category Classification Results:\")\n",
                "print(classification_report(y_category_test, y_cat_pred_test))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model Interpretability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Feature importance for price prediction\n",
                "feature_importance = pd.DataFrame({\n",
                "    'feature': X_combined.columns,\n",
                "    'importance': rf_price.feature_importances_\n",
                "}).sort_values('importance', ascending=False)\n",
                "\n",
                "# Plot top 20 features\n",
                "plt.figure(figsize=(10, 8))\n",
                "top_features = feature_importance.head(20)\n",
                "plt.barh(range(len(top_features)), top_features['importance'])\n",
                "plt.yticks(range(len(top_features)), top_features['feature'])\n",
                "plt.xlabel('Feature Importance')\n",
                "plt.title('Top 20 Features for Price Prediction')\n",
                "plt.gca().invert_yaxis()\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"Top 10 most important features:\")\n",
                "print(feature_importance.head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Cross-validation for price prediction\n",
                "cv_scores = cross_val_score(rf_price, X_train, y_train, cv=5, scoring='r2')\n",
                "print(f\"Cross-validation R² scores: {cv_scores}\")\n",
                "print(f\"Mean CV R²: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
                "\n",
                "# Prediction vs actual plot\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.scatter(y_test, y_pred_test, alpha=0.5)\n",
                "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
                "plt.xlabel('Actual Log Price')\n",
                "plt.ylabel('Predicted Log Price')\n",
                "plt.title('Price Prediction: Actual vs Predicted')\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "residuals = y_test - y_pred_test\n",
                "plt.scatter(y_pred_test, residuals, alpha=0.5)\n",
                "plt.axhline(y=0, color='r', linestyle='--')\n",
                "plt.xlabel('Predicted Log Price')\n",
                "plt.ylabel('Residuals')\n",
                "plt.title('Residual Plot')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save Models and Artifacts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Save models and preprocessing artifacts\n",
                "model_artifacts = {\n",
                "    'price_model': rf_price,\n",
                "    'category_model': rf_category,\n",
                "    'tfidf_vectorizer': tfidf_vectorizer,\n",
                "    'scaler': scaler,\n",
                "    'label_encoders': {\n",
                "        'company': le_company,\n",
                "        'category': le_category\n",
                "    },\n",
                "    'feature_names': X_combined.columns.tolist(),\n",
                "    'numerical_features': numerical_features\n",
                "}\n",
                "\n",
                "# Save using joblib\n",
                "joblib.dump(model_artifacts, '../models/boq_models.pkl')\n",
                "print(\"Models saved successfully!\")\n",
                "\n",
                "# Save model performance metrics\n",
                "metrics = {\n",
                "    'price_model_metrics': {\n",
                "        'test_rmse': float(test_rmse),\n",
                "        'test_r2': float(test_r2),\n",
                "        'cv_mean_r2': float(cv_scores.mean()),\n",
                "        'cv_std_r2': float(cv_scores.std())\n",
                "    },\n",
                "    'feature_importance': feature_importance.head(20).to_dict('records')\n",
                "}\n",
                "\n",
                "with open('../models/model_metrics.json', 'w') as f:\n",
                "    json.dump(metrics, f, indent=2)\n",
                "\n",
                "print(\"Model metrics saved!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model Testing Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "def predict_price(description, company, category, compatibility_count=0, spec_count=0):\n",
                "    \"\"\"Predict price for a new product\"\"\"\n",
                "    \n",
                "    # Create feature vector\n",
                "    features = {\n",
                "        'description_length': len(description),\n",
                "        'word_count': len(description.split()),\n",
                "        'company_encoded': le_company.transform([company])[0] if company in le_company.classes_ else 0,\n",
                "        'category_encoded': le_category.transform([category])[0] if category in le_category.classes_ else 0,\n",
                "        'compatibility_count': compatibility_count,\n",
                "        'spec_count': spec_count\n",
                "    }\n",
                "    \n",
                "    # TF-IDF features\n",
                "    tfidf_vector = tfidf_vectorizer.transform([description])\n",
                "    tfidf_features = {f'tfidf_{i}': tfidf_vector[0, i] for i in range(tfidf_vector.shape[1])}\n",
                "    \n",
                "    # Combine features\n",
                "    all_features = {**features, **tfidf_features}\n",
                "    feature_vector = np.array([all_features.get(col, 0) for col in X_combined.columns]).reshape(1, -1)\n",
                "    \n",
                "    # Predict\n",
                "    log_price = rf_price.predict(feature_vector)[0]\n",
                "    price = np.expm1(log_price)  # Inverse of log1p\n",
                "    \n",
                "    return price\n",
                "\n",
                "# Test the function\n",
                "test_price = predict_price(\n",
                "    description=\"High-quality wireless microphone with noise cancellation\",\n",
                "    company=\"Shure\",\n",
                "    category=\"audio\",\n",
                "    compatibility_count=5,\n",
                "    spec_count=8\n",
                ")\n",
                "\n",
                "print(f\"Predicted price for test product: ${test_price:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary and Next Steps"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "print(\"=== Model Training Summary ===\")\n",
                "print(f\"Dataset size: {len(df)} products\")\n",
                "print(f\"Products with prices: {len(df_priced)}\")\n",
                "print(f\"Feature dimensions: {X_combined.shape[1]}\")\n",
                "print(f\"Price prediction R²: {test_r2:.4f}\")\n",
                "print(f\"Cross-validation R²: {cv_scores.mean():.4f}\")\n",
                "\n",
                "print(\"\\n=== Next Steps ===\")\n",
                "print(\"1. Integrate models into BOQ generator web application\")\n",
                "print(\"2. Implement real-time price updates and model retraining\")\n",
                "print(\"3. Add more sophisticated recommendation algorithms\")\n",
                "print(\"4. Collect user feedback for model improvement\")\n",
                "print(\"5. Implement A/B testing for model versions\")\n",
                "\n",
                "print(\"\\n=== Model Files Created ===\")\n",
                "print(\"- ../models/boq_models.pkl (trained models and preprocessors)\")\n",
                "print(\"- ../models/model_metrics.json (performance metrics)\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
